# Unsupervised Real-world Image Super Resolution via Domain-distance Aware Training



### 内容与背景介绍

CVPR 2021的一篇文章

[DASR_code](https://github.com/ShuhangGu/DASR.)

主要就是做unsupervised超分，通过一个unpaired HR-LR对(即图片内容不匹配，比如高清的大楼照片和低清的人脸)来训练模型对LR进行超分



https://www.bilibili.com/video/BV1PT4y1d7b4/

采用bibucub和bilinear等方法进行下采样再通过深度学习网络进行重建时，往往会出现严重的伪影

![image-20211125101453870](C:/Users/46752/OneDrive/mark/picture/image-20211125101453870.png)

**因为Synthetic LR难以对真实场景进行模拟，与Real-word LR有差距（domain gap 他俩就不是一类图片），所以学习Synthetic到GT HR之间的映射，应用到真实场景中就会效果不好，泛化性能有限**

在数据集的构造上就存在以下两个问题：

- 有了real-world LR的图片很难找到对应的HR
- 有real-world HR去构造LR的时候一些下采样的方法又难以模拟real-world LR

所以有了blind SR这个领域，给定一组无对应关系的real-world LR和real-world HR，让超分网络能够学习到他与与之对应的HR的对应关系

**一般的盲超分或者是real-world SR或者是unsupervsed SR,目的就是将real-world HR下采样为尽可能逼近真实图片的real-world LR，然后就构造出了配对的LR-HR对，这样训练出来的神经网络模型就能从真实的LR超分至真实的HR**

![image-20211125102857370](https://raw.githubusercontent.com/DejaVuyan/blog.img/main/202206021052359.png)

那么进行degrade或者说downsample的方法有：

![image-20211125103314482](https://raw.githubusercontent.com/DejaVuyan/blog.img/main/202206021052366.png)

- 调整相机的焦距构造LR-HR pair(费时费力)
- 通过先验知识 Blur Kernels和一系列的步骤去模拟下采样的过程(泛化性不强)
- 通过神经网络去学习HR和LR之间的关系，比如CycleGan(生成数据与real-world的domain gap依然存在)



### 原理简介

整体的框架如下所示

![image-20220602103017117](https://raw.githubusercontent.com/DejaVuyan/blog.img/main/202206021030245.png)



分为两个模型



##### 1.DSN（下采样模型）

![image-20220602103604847](https://raw.githubusercontent.com/DejaVuyan/blog.img/main/202206021036942.png)

目的是通过模型将HR下采样至LR,并且尽可能的使得生成的LR去贴近real LR，文中HR为xi而y^r是real LR，y^g是生成出的LR，y^b是Bicubic下采样的LR

通过L_con(L1 Loss)和L_per(视觉loss)保证纹理，来保证内容上的一致，使用Ladv和判别器来减小domain gap



在判别器方面：

不匹配内容的训练，容易产生伪影，所以只输入高频细节到判别器中，所以只将高频部分输入到判别器中进行判别

![image-20220602103655901](https://raw.githubusercontent.com/DejaVuyan/blog.img/main/202206021036987.png)

GBFS uses the residual between original and Gaussian blurred images to extract high-frequency component, our WFS approach adopts Wavelet transform to obtain high-frequency component, RGB means we introduce GAN loss directly on RGB images. 

在细节上通过GBFS(Gaussian Blur Frequency Separation)来提取出高频信息，然后使用小波变换来获取高频特征，最后使用GAN loss去学习他





![image-20220602104046826](https://raw.githubusercontent.com/DejaVuyan/blog.img/main/202206021040904.png)



判别器最终会对每一个patch输出来一个置信度，来判别生成的LR是否符合real SR的分布



##### 2.SRN(超分网络)

是由监督部分和半监督部分分别形成 Loss然后加权组合

![image-20220602104853109](https://raw.githubusercontent.com/DejaVuyan/blog.img/main/202206021048279.png)



1.监督训练，用上一步模型生成的LR图片和真实的HR图片做一个超分，并且乘上domain distance score作为权重

2.半监督训练，用真实的LR图像和HR图像进行非配对学习，因为内容上不匹配所以只提取高频部分构造对抗损失

两个部分进行加权构成总的loss去训练，这样 **利用不同的数据特点构造不同的loss就利用到了不同的数据**



### 实验设置

有两个人为构造的复杂下采样的数据集

realSR dataset和Camera SR dataset

还有DIV2K的高清图像

有一个paired HR-LR对，是RealSR dataset,用来验证图片的效果，但是具体实验使用的unpaired HR-LR图片对，RealSR的LR和DIV2K的HR



### 总结和想法

最巧妙的是利用了图像的高频特征和L_adv去学习分布而用L1 loss去保持内容的一致性，将风格转换类GAN的想法迁移过来做一个超分，但是又不是直接用cycleGAN



判别器是一个patch D，这里就不能用U-net之类的去做一个逐像素的判别，因为不能拿判断图片的像素是不是符合real SR的分布吧，有点不合理

**但是是否可以将这种权重的形式使用attention机制去作用在训练过程中呢？**



增加可信度：添加更多的例子在补充文件中，并且开源代码有利于别人复现